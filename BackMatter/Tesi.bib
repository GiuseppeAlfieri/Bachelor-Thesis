@online{changDesignFundDiffusion2023,
  title = {On the {{Design Fundamentals}} of {{Diffusion Models}}: {{A Survey}}},
  shorttitle = {On the {{Design Fundamentals}} of {{Diffusion Models}}},
  author = {Chang, Ziyi and Koulieris, George Alex and Shum, Hubert P. H.},
  date = {2023-10-19},
  eprint = {2306.04542},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.04542},
  abstract = {Diffusion models are generative models, which gradually add and remove noise to learn the underlying distribution of training data for data generation. The components of diffusion models have gained significant attention with many design choices proposed. Existing reviews have primarily focused on higher-level solutions, thereby covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review on component-wise design choices in diffusion models. Specifically, we organize this review according to their three key components, namely the forward process, the reverse process, and the sampling procedure. This allows us to provide a fine-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the applicability of design choices, and the implementation of diffusion models.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\Giuseppe\Zotero\storage\Z2EWXQJW\2306.html}
}

@online{chenImportanceNoiseScheduling2023,
  title = {On the {{Importance}} of {{Noise Scheduling}} for {{Diffusion Models}}},
  author = {Chen, Ting},
  date = {2023-05-21},
  eprint = {2301.10972},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2301.10972},
  abstract = {We empirically study the effect of noise scheduling strategies for denoising diffusion generative models. There are three findings: (1) the noise scheduling is crucial for the performance, and the optimal one depends on the task (e.g., image sizes), (2) when increasing the image size, the optimal noise scheduling shifts towards a noisier one (due to increased redundancy in pixels), and (3) simply scaling the input data by a factor of \$b\$ while keeping the noise schedule function fixed (equivalent to shifting the logSNR by \$\textbackslash log b\$) is a good strategy across image sizes. This simple recipe, when combined with recently proposed Recurrent Interface Network (RIN), yields state-of-the-art pixel-based diffusion models for high-resolution images on ImageNet, enabling single-stage, end-to-end generation of diverse and high-fidelity images at 1024\$\textbackslash times\$1024 resolution (without upsampling/cascades).},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning,Computer Science - Multimedia},
  file = {C:\Users\Giuseppe\Zotero\storage\C5YRTCBS\2301.html}
}

@book{conteFenomeniAleatori2006,
  title = {Fenomeni aleatori},
  author = {Conte, Ernesto and Galdi, Carmela},
  date = {2006-12-01},
  publisher = {{Aracne}},
  abstract = {Un'introduzione allo studio del calcolo delle probabilità che cerca di bilanciare il necessario rigore matematico con la semplicità espositiva},
  isbn = {978-88-548-0813-3},
  langid = {italian},
  pagetotal = {316}
}

@inreference{DALLE2023,
  title = {{{DALL-E}}},
  booktitle = {Wikipedia},
  date = {2023-12-02T17:09:40Z},
  url = {https://en.wikipedia.org/w/index.php?title=DALL-E&oldid=1187974775},
  abstract = {DALL·E, DALL·E 2, and DALL·E 3 are text-to-image models developed by OpenAI using deep learning methodologies to generate digital images from natural language descriptions, called "prompts". The original DALL·E was revealed by OpenAI in a blog post in 5 January 2021, and uses a version of GPT-3 modified to generate images. In 6 April 2022, OpenAI announced DALL·E 2, a successor designed to generate more realistic images at higher resolutions that "can combine concepts, attributes, and styles". In September 2023, OpenAI announced their latest image model, DALL·E 3, capable of understanding "significantly more nuance and detail" than previous iterations.On 20 July 2022, DALL·E 2 entered into a beta phase with invitations sent to 1 million waitlisted individuals; users could generate a certain number of images for free every month and may purchase more. Access had previously been restricted to pre-selected users for a research preview due to concerns about ethics and safety. On 28 September 2022, DALL·E 2 was opened to everyone and the waitlist requirement was removed.In early November 2022, OpenAI released DALL·E 2 as an API, allowing developers to integrate the model into their own applications. Microsoft unveiled their implementation of DALL·E 2 in their Designer app and Image Creator tool included in Bing and Microsoft Edge. The API operates on a cost per image basis, with prices varying depending on image resolution. Volume discounts are available to companies working with OpenAI’s enterprise team.DALL·E 3 was released natively into ChatGPT for ChatGPT Plus and ChatGPT Enterprise customers in October 2023, with availability via OpenAI's API  and "Labs" platform provided in early November. Microsoft implemented the model in Bing's Image Creator tool and plans to implement it into their Designer app.The software's name is a portmanteau of the names of animated robot Pixar character WALL-E and the Spanish surrealist artist Salvador Dalí.},
  langid = {english},
  annotation = {Page Version ID: 1187974775}
}

@book{deisenrothMML2020,
  title = {Mathematics for Machine Learning},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  date = {2020-04-23},
  series = {Studies in Natural Language Processing},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge ; New York, NY}},
  doi = {10.1017/9781108679930},
  url = {https://www.cambridge.org/highereducation/books/mathematics-for-machine-learning/5EE57FD1CFB23E6EB11E130309C7EF98},
  abstract = {The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts. Every chapter includes worked examples and exercises to test understanding. Programming tutorials are offered on the book's web site.},
  isbn = {978-1-108-67993-0},
  langid = {Inglese},
  pagetotal = {390},
  file = {C:\Users\Giuseppe\Zotero\storage\3CU4DFU6\5EE57FD1CFB23E6EB11E130309C7EF98.html}
}

@online{dhariwal2021,
  title = {Diffusion {{Models Beat GANs}} on {{Image Synthesis}}},
  author = {Dhariwal, Prafulla and Nichol, Alex},
  date = {2021-06-01},
  eprint = {2105.05233},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2105.05233},
  abstract = {We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128\$\textbackslash times\$128, 4.59 on ImageNet 256\$\textbackslash times\$256, and 7.72 on ImageNet 512\$\textbackslash times\$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256\$\textbackslash times\$256 and 3.85 on ImageNet 512\$\textbackslash times\$512. We release our code at https://github.com/openai/guided-diffusion},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\Giuseppe\Zotero\storage\AD883UYD\2105.html}
}

@incollection{fellerTheoryStochasticProcesses1949,
  title = {On the {{Theory}} of {{Stochastic Processes}}, with {{Particular Reference}} to {{Applications}}},
  booktitle = {Proceedings of the [{{First}}] {{Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}},
  author = {Feller, W.},
  date = {1949-01-01},
  volume = {1},
  pages = {403--433},
  publisher = {{University of California Press}},
  url = {https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-First-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/On-the-Theory-of-Stochastic-Processes-with-Particular-Reference-to/bsmsp/1166219215}
}

@book{fosterGenerativeDeepLearning2023,
  title = {Generative Deep Learning: Teaching Machines to Paint, Write, Compose, and Play},
  shorttitle = {Generative Deep Learning},
  author = {Foster, David and Friston, Karl},
  date = {2023-05-31},
  edition = {2° edizione},
  publisher = {{O'Reilly Media, Inc.}},
  location = {{Beijing ; Boston}},
  abstract = {Generative AI is the hottest topic in tech. This practical book teaches machine learning engineers and data scientists how to use TensorFlow and Keras to create impressive generative deep learning models from scratch, including variational autoencoders (VAEs), generative adversarial networks (GANs), Transformers, normalizing flows, energy-based models, and denoising diffusion models. The book starts with the basics of deep learning and progresses to cutting-edge architectures. Through tips and tricks, you'll understand how to make your models learn more efficiently and become more creative. Discover how VAEs can change facial expressions in photosTrain GANs to generate images based on your own datasetBuild diffusion models to produce new varieties of flowersTrain your own GPT for text generationLearn how large language models like ChatGPT are trainedExplore state-of-the-art architectures such as StyleGAN2 and ViT-VQGAN Compose polyphonic music using Transformers and MuseGANUnderstand how generative world models can solve reinforcement learning tasksDive into multimodal models such as DALL.E 2, Imagen, and Stable Diffusion This book also explores the future of generative AI and how individuals and companies can proactively begin to leverage this remarkable new technology to create competitive advantage.},
  isbn = {978-1-09-813418-1},
  langid = {Inglese},
  pagetotal = {426}
}

@book{goodfellowDeepLearning2016,
  title = {Deep {{Learning}}},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016-11-18},
  edition = {Illustrated edition},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
  isbn = {978-0-262-03561-3},
  langid = {english},
  pagetotal = {800}
}

@online{goodfellowGAN2014,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014-06-10},
  eprint = {1406.2661},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1406.2661},
  url = {http://arxiv.org/abs/1406.2661},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\Giuseppe\Zotero\storage\P7KNXQ97\1406.html}
}

@online{goodfellowNIPS2016Tutorial2017,
  title = {{{NIPS}} 2016 {{Tutorial}}: {{Generative Adversarial Networks}}},
  shorttitle = {{{NIPS}} 2016 {{Tutorial}}},
  author = {Goodfellow, Ian},
  date = {2017-04-03},
  eprint = {1701.00160},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1701.00160},
  abstract = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {C:\Users\Giuseppe\Zotero\storage\HFLV5FUP\1701.html}
}

@online{GoogleColaboratory,
  title = {Google Colaboratory},
  url = {https://colab.research.google.com/},
  langid = {italian},
  file = {C:\Users\Giuseppe\Zotero\storage\K24BKWY7\colab.research.google.com.html}
}

@inproceedings{heuselGANsTrainedTwo2017,
  title = {{{GANs Trained}} by a {{Two Time-Scale Update Rule Converge}} to a {{Local Nash Equilibrium}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://papers.nips.cc/paper/2017/hash/8a1d694707eb0fefe65871369074926d-Abstract.html},
  abstract = {Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the `Fréchet Inception Distance'' (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.}
}

@inproceedings{ho2020,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  date = {2020},
  volume = {33},
  pages = {6840--6851},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper_files/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.}
}

@online{IntroductionDiffusionModels2022,
  title = {Introduction to {{Diffusion Models}} for {{Machine Learning}}},
  date = {2022-05-12T15:19:03},
  url = {https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/},
  abstract = {The meteoric rise of Diffusion Models is one of the biggest developments in Machine Learning in the past several years. Learn everything you need to know about Diffusion Models in this easy-to-follow guide.},
  langid = {english},
  organization = {{News, Tutorials, AI Research}},
  file = {C:\Users\Giuseppe\Zotero\storage\QXXIBZFC\diffusion-models-for-machine-learning-introduction.html}
}

@online{kingmaVAE2022,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2022-12-10},
  eprint = {1312.6114},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1312.6114},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\Giuseppe\Zotero\storage\XBKXXBDI\1312.html}
}

@online{Midjourney,
  title = {Midjourney},
  url = {https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F},
  abstract = {An independent research lab exploring new mediums of thought and expanding the imaginative powers of the human species.},
  organization = {{Midjourney}},
  file = {C:\Users\Giuseppe\Zotero\storage\BB7MRX9G\home.html}
}

@online{nain2022,
  title = {The {{Latent}}: {{Code}} the {{Maths}} - {{A}} Deep Dive into {{DDPMs}}},
  shorttitle = {The {{Latent}}},
  author = {Nain, Aakash Kumar},
  date = {2022-09-02},
  url = {https://magic-with-latents.github.io/latent/posts/ddpms/part3/},
  langid = {english},
  file = {C:\Users\Giuseppe\Zotero\storage\W3HQIEB4\part3.html}
}

@inproceedings{nicholImprovedDenoisingDiffusion2021a,
  title = {Improved {{Denoising Diffusion Probabilistic Models}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Nichol, Alexander Quinn and Dhariwal, Prafulla},
  date = {2021-07-01},
  pages = {8162--8171},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/nichol21a.html},
  abstract = {Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code and pre-trained models at https://github.com/openai/improved-diffusion.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@online{ronnebergerUNet2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  date = {2015-05-18},
  eprint = {1505.04597},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1505.04597},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\Giuseppe\Zotero\storage\T8JDLF7K\1505.html}
}

@online{royBeginnerGuideDiffusion,
  title = {A {{Beginner}}'s {{Guide}} to {{Diffusion Models}}: {{Understanding}} the {{Basics}} and {{Beyond}}},
  shorttitle = {A {{Beginner}}'s {{Guide}} to {{Diffusion Models}}},
  author = {Roy, Subhradip},
  url = {https://roysubhradip.hashnode.dev/a-beginners-guide-to-diffusion-models-understanding-the-basics-and-beyond},
  abstract = {From Psychology to Machine Learning : The Evolution of Diffusion Models and Their Impact on Decision-Making : The growth of the Diffusion Model can be attributed to the recent breakthrough in the field of AI generative artworks. In this essay, I'll s...},
  langid = {english},
  organization = {{Subhradip Roy's Blog}},
  file = {C:\Users\Giuseppe\Zotero\storage\WMPZIJAW\a-beginners-guide-to-diffusion-models-understanding-the-basics-and-beyond.html}
}

@inproceedings{sohl-dickstein2015,
  title = {Deep {{Unsupervised Learning}} Using {{Nonequilibrium Thermodynamics}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  date = {2015-06-01},
  pages = {2256--2265},
  publisher = {{PMLR}},
  issn = {1938-7228},
  url = {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english}
}

@inproceedings{songImprovedTechniquesTraining2020,
  title = {Improved {{Techniques}} for {{Training Score-Based Generative Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Song, Yang and Ermon, Stefano},
  date = {2020},
  volume = {33},
  pages = {12438--12448},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/hash/92c3b916311a5517d9290576e3ea37ad-Abstract.html},
  abstract = {Score-based generative models can produce high quality image samples comparable to GANs, without requiring adversarial optimization. However, existing training procedures are limited to images of low resolution (typically below 32 x 32), and can be unstable under some settings. We provide a new theoretical analysis of learning and sampling from score models in high dimensional spaces, explaining existing failure modes and motivating new solutions that generalize across datasets.  To enhance stability, we also propose to maintain an exponential moving average of model weights. With these improvements, we can effortlessly scale score-based generative models to images with unprecedented resolutions ranging from 64 x 64 to 256 x 256. Our score-based models can generate high-fidelity samples that rival best-in-class GANs on various image datasets, including CelebA, FFHQ, and multiple LSUN categories.}
}

@online{szegedyRethinkingInceptionArchitecture2015,
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  date = {2015-12-11},
  eprint = {1512.00567},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1512.00567},
  abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2\% top-1 and 5.6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5\% top-5 error on the validation set (3.6\% error on the test set) and 17.3\% top-1 error on the validation set.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\Giuseppe\Zotero\storage\3JVTVX8B\1512.html}
}

@online{vaibhavsinghInDepthGuideDenoising2023,
  title = {An {{In-Depth Guide}} to {{Denoising Diffusion Probabilistic Models}} – {{From Theory}} to {{Implementation}}},
  author = {{Vaibhav Singh}},
  date = {2023-03-06T14:00:00+00:00},
  url = {https://learnopencv.com/denoising-diffusion-probabilistic-models/},
  abstract = {An in-depth explanation of the theory and math behind denoising diffusion probabilistic models (DDPMs) and implementing them from scratch in PyTorch.},
  langid = {american},
  file = {C:\Users\Giuseppe\Zotero\storage\ZDU2TSMA\denoising-diffusion-probabilistic-models.html}
}

@online{wilsonAdobeSellingFake2023,
  title = {Adobe Is Selling Fake {{AI}} Images of the War in {{Israel-Gaza}}},
  author = {Wilson, Cam},
  date = {2023-11-01T00:30:01+00:00},
  url = {https://www.crikey.com.au/2023/11/01/israel-gaza-adobe-artificial-intelligence-images-fake-news/},
  abstract = {Online publications have used a photorealistic image of a missile attack from Adobe Stock without marking it as fake.},
  langid = {american},
  organization = {{Crikey}},
  file = {C:\Users\Giuseppe\Zotero\storage\I73KZJZC\israel-gaza-adobe-artificial-intelligence-images-fake-news.html}
}
